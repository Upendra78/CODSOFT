{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0e92fe-0c38-4779-8544-6e65d95a405d",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction for Banking Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87ca93-0b7a-40c0-b637-76f87ae33421",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bb2d7-da23-4f85-b9b2-7ce8fdaa721e",
   "metadata": {},
   "source": [
    "# 1. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c73b3-2ba4-48fa-9e8a-c0fe26bcd9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "print(\"Dataset shape: \", df.shape)\n",
    "print('ramdom 5 rows:')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42d183-229a-4ba8-b63f-6edc823a2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Info: \")\n",
    "df.info()\n",
    "print()\n",
    "print('Basic Statestics: ')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894024ca-eaca-4c9c-a50a-44751a250705",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b8fe2-f124-479e-a40b-08c054cea688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Names: \\n\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38937d-3894-4e4d-810b-1100ed54dba0",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0a43a-be1b-44b5-ad51-b139fb2d71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "df_cleaned = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis =1)\n",
    "# check cleaned dataset\n",
    "df_cleaned.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3223632-926c-4e1b-8074-b2688236af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values in cleanded dataset\n",
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5a4fa-8f41-4f2e-927f-0667b35aae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatype\n",
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e3fb9-90a4-4b13-8429-62843c1cabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values for categorical columns\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_cols.tolist())\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n {col}: {df_cleaned[col].unique()}\")\n",
    "    print(f\"Value counts: \\n {df_cleaned[col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33c94f-99e1-4f17-9026-cde70c74c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the target variable distribution \n",
    "print(\"Target variable distribution: \")\n",
    "print(df_cleaned[\"Exited\"].value_counts())\n",
    "print(f\"\\nChurn Rate: {df_cleaned['Exited'].mean(): .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e8b68-9c3d-4b8d-8521-8e26bb8ecb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target variable\n",
    "plt.figure(figsize =(8,6))\n",
    "sns.countplot(data= df_cleaned, x= 'Exited')\n",
    "plt.title('Distribution of Churn (Exited)')\n",
    "plt.xlabel('Exited (0= No, 1 =Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972cbeb-2006-499d-ace2-20bbedac9e3b",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a4a00-fa10-4cea-8c81-5ee13e6d2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize =(18, 12))\n",
    "# 1. geography vs Churn\n",
    "sns.countplot(data= df_cleaned, x= 'Geography', hue = 'Exited', ax = axes[0,0])\n",
    "axes[0,0].set_title('Churn by Geography')\n",
    "axes[0,0].set_xlabel('Geography')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# 2. Gender vs Churn\n",
    "sns.countplot(data = df_cleaned, x= 'Gender', hue = 'Exited', ax= axes[0,1])\n",
    "axes[0,1].set_title('Churn by Gender')\n",
    "axes[0,1].set_xlabel('Gender')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "\n",
    "# 3. HasCrCard vs Churn\n",
    "sns.countplot(data= df_cleaned, x= 'HasCrCard', hue = 'Exited', ax= axes[0,2])\n",
    "axes[0,2].set_title('Churn by Credit Card Ownership')\n",
    "axes[0,2].set_xlabel('Has Credit Card (0= No, 1 =Yes)')\n",
    "axes[0,2].set_ylabel('Count')\n",
    "\n",
    "# 4. IsActiveMember vs Churn\n",
    "sns.countplot(data= df_cleaned, x = 'IsActiveMember', hue='Exited', ax= axes[1,0])\n",
    "axes[1,0].set_title('Churn by Active Membership')\n",
    "axes[1,0].set_xlabel('Is Active Member (0= No, 1= Yes)')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "\n",
    "# 5. NumOfProducts vs Churn\n",
    "sns.countplot(data= df_cleaned, x = 'NumOfProducts', hue = 'Exited', ax= axes[1,1])\n",
    "axes[1,1].set_title('Churn by Number of Products')\n",
    "axes[1,1].set_xlabel('Number')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "\n",
    "# 6. Tenure vs Churn\n",
    "df_cleaned.groupby('Tenure')['Exited'].mean().plot(kind = 'line', ax = axes[1,2], marker= 'o')\n",
    "axes[1,2].set_title('Churn Rate by Tenure')\n",
    "axes[1,2].set_xlabel('Tenure (Years)')\n",
    "axes[1,2].set_ylabel('Churn Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10deeac-02a9-4090-ae7d-57201b30faf5",
   "metadata": {},
   "source": [
    "# Numerical features analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686c12a-082f-4849-9b9d-f68e93edec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n",
    "fig, axes= plt.subplots(2,2, figsize= (15,10))\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    row, col_idx= idx // 2, idx %2\n",
    "    sns.boxplot(data = df_cleaned, x= 'Exited', y = col, ax= axes[row, col_idx])\n",
    "    axes[row, col_idx].set_title(f'{col} vs Churn')\n",
    "    axes[row, col_idx].set_xlabel('Exited (0= No, 1= Yes)')\n",
    "    axes[row, col_idx].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5f1e9-32b4-4723-bebe-b7c4ef9ed2eb",
   "metadata": {},
   "source": [
    "# Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fad200-e4a2-4935-ab15-84349cb631a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (12,10))\n",
    "# Encode categorical variables for correlation analysis\n",
    "df_encoded = df_cleaned.copy()\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "corr_matrix = df_encoded.corr()\n",
    "sns.heatmap(corr_matrix, annot= True, fmt='.2f', cmap= 'coolwarm', center = 0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a980acf-4e6b-482b-ab1d-3023ee2b0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top correlations with target \n",
    "print(\"Top correlations with Exited (Churn): \")\n",
    "corr_with_target = corr_matrix['Exited'].sort_values(ascending = False)\n",
    "print(corr_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa45a3e-82d0-4797-8e77-8ed03647e7dd",
   "metadata": {},
   "source": [
    "# 4. Features Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df618c13-a273-46d0-bb91-39373081fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198effc-3c67-42cf-b42c-5281bd08530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical variables using one-hot encoding\n",
    "df_processed = pd.get_dummies(df_processed, columns=['Geography', 'Gender'], drop_first= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ea0b3-1a76-443b-bd12-3e88b3bc0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display processed dataset\n",
    "print(\"Processed dataset shape:\", df_processed.shape)\n",
    "print(\"\\nProcessed columns: \")\n",
    "print(df_processed.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d20a5b-2869-4767-80c1-dd392bdaddc6",
   "metadata": {},
   "source": [
    "# Split features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a010f31-24a8-4d24-9d28-58836140ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_processed.drop('Exited', axis = 1)\n",
    "y= df_processed['Exited']\n",
    "print('Features shape:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2a06c-0c16-4616-bee6-1ca851d54932",
   "metadata": {},
   "source": [
    "# Split into train and test ssets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e61e8-2c68-4a06-b98f-f67b20c0b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=  0.2, random_state= 42, stratify =y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cca93d-378c-4f37-9b89-ae5cb38b9d7d",
   "metadata": {},
   "source": [
    "# Scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347de706-4c8a-4a51-9c96-264b445e31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Identify numerical columns (excluding the encoded ones)\n",
    "num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "# Fit and transform on training data, transform on test data\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "print(\"Scaling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a813a4a-b9b1-457c-8e66-c7f5f1fc4787",
   "metadata": {},
   "source": [
    "# 5. Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b475104-e4a0-4586-b010-d066ce30bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution \n",
    "print(\"Before handling imbalance: \")\n",
    "print(f\"Class 0 (No Churn): {sum(y_train == 0)} samples\")\n",
    "print(f\"Class 1 (Churn): {sum(y_train==1)} samples\")\n",
    "print(f\"Churn rates: {y_train.mean():.2%}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb0342-c1cf-44e0-94e9-b8599eaac04b",
   "metadata": {},
   "source": [
    "# Option 1: SMOTE (Synthetic Minority Over-sampling Technique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f7d77-376f-4966-8ac9-d4fd1a846496",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state= 42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nAfter SMOTE: \")\n",
    "print(f\" Class 0 (No Churn): {sum(y_train_smote == 0)} samples\")\n",
    "\n",
    "print(f\" Class 1 (Churn): {sum(y_train_smote == 1)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef987f-b038-4f6b-b16b-fc6040cd402b",
   "metadata": {},
   "source": [
    "# 6. Model Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80205df4-287c-4cd8-bace-c2d5e5ad26fc",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede5e15-0b47-4d3b-91ed-ebfbbd2f57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\n",
    "    'Logistic Regression': LogisticRegression(random_state = 42, max_iter = 1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state= 42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state= 42),\n",
    "    'Random Forest': RandomForestClassifier(random_state= 42, n_jobs=1)\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524cd8d-cf70-4194-bdbc-bfbd2f36a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each model\n",
    "results= {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    if model_name == 'Logistic Regression':\n",
    "        # Use original data for Logistic Regression (works better without SMOTE sometimes)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred= model.predict(X_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        # Use SMOTE data for tree-based models\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(X_test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6882b9-84b2-413c-b1e6-c13a3a614598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfdfbfc-20c5-4e18-aeeb-5ff70b602438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "results[model_name]= {\n",
    "    'model': model,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'roc_auc': roc_auc,\n",
    "    'y_pred': roc_auc,\n",
    "    'y_pred': y_pred,\n",
    "    'y_pred_prob': y_pred_prob\n",
    "}\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall: .4f}\")\n",
    "print(f\"F1-Score: {f1: .4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ff0a4-6958-43ce-ac2e-11983abeba83",
   "metadata": {},
   "source": [
    "# 7. Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa4ee1-c4d5-467a-86d5-c4258f41995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a comparison DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1-Score': [results[m]['f1'] for m in results],\n",
    "    'ROC-AUC': [results[m]['roc_auc'] for m in results]\n",
    "})\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df.sort_values('F1-Score', ascending =False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab2644-a649-4461-82cc-25293544a134",
   "metadata": {},
   "source": [
    "# Visualize model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c943080-c9cd-42e5-abf2-5b4844de3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2 , figsize= (15,12))\n",
    "# 1. Bar chart for accuracy and F1-Score\n",
    "metrics_to_plot = ['Accuracy', 'F1-Score', 'Recall', 'ROC-AUC']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    row, col = idx//2, idx %2\n",
    "    axes[row, col].bar(results_df['Model'], results_df[metric], color= colors[idx])\n",
    "    axes[row, col].set_title(f'{metric} Comparison')\n",
    "    axes[row, col].set_ylabel(metric)\n",
    "    axes[row, col].tick_params(axis= 'x', rotation =45)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(results_df[metric]):\n",
    "        axes[row, col].text(i,v+0.01, f'{v: .3f}', ha= 'center', va= 'bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b392023-1d35-44a3-862c-dc4cb7b775c4",
   "metadata": {},
   "source": [
    "# Confusion matrices for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a54c5f-25a4-4856-9909-08e87b9a26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( figsize=(15,12))\n",
    "for idx, (model_name, result) in enumerate(results.items()):\n",
    "    row, col =idx // 2,  idx % 2\n",
    "    cm= confusion_matrix(y_test, result['y_pred'])\n",
    "    sns.heatmap(cm, annot = True, fmt='d', cmap= 'Blues', ax= axes[row,col])\n",
    "    axes[row, col].set_title(f'Confusion Matrix - {model_name}')\n",
    "    axes[row, col].set_xlabel('Predicted')\n",
    "    axes[row, col].set_ylabel('Actual')\n",
    "    axes[row, col].set_xticklabels(['No Churn', 'Churn'])\n",
    "    axes[row, col].set_yticklabels(['No Churn', 'Churn'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dc09e-1241-4d20-bbf4-869187257f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for model_name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_prob'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label= f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0,1],[0,1], color = 'navy', lw=2, linestyle= '--', label = 'Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparision')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78cafd-c55a-4be5-9e2a-1738e429e94a",
   "metadata": {},
   "source": [
    "# 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9ff01-21f8-49c9-89b5-8fac9535d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results[\"Random Forest\"]['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print('Top 10 Most Important Features:')\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589284a3-a01e-4c03-87a4-c251e7bc7ce6",
   "metadata": {},
   "source": [
    "# Visualize feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b7dd9-35b7-4772-be88-8950075da67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "sns.barplot(data=feature_importance.head(15), x= 'importance', y ='feature')\n",
    "plt.title('Top 15 Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b386c8-0177-4a6a-b68d-15e9b7077d6a",
   "metadata": {},
   "source": [
    "# 9. Hyperparameter tuning for bet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2be58-5613-436c-a0ba-02f46823fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hyperparameter tuning for Random Forest\")\n",
    "# Define parameter grid\n",
    "param_grid ={\n",
    "    'n_estimators': [100,200,300],\n",
    "    'max_depth': [10,20, 30, None],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,2,4],\n",
    "    'max_features':['sqrt','log2']\n",
    "}\n",
    "# Initialize grid search \n",
    "rf = RandomForestClassifier(random_state = 42, n_jobs =-1)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = rf,\n",
    "    param_grid = param_grid,\n",
    "    cv = 3,\n",
    "    n_jobs = -1,\n",
    "    verbose = 1,\n",
    "    scoring = 'f1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11493a-e5bf-47c8-ac3e-4935c203de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit grid search (using SMOTE data)\n",
    "print(\"Performing gred search...\")\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get best parameteres and model\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2f561-4364-45c8-a1fd-7ff06e89366f",
   "metadata": {},
   "source": [
    "# Evaluate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b669bfd-ce4f-47d8-ae13-1835a73f016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_tuned = best_rf.predict(X_test_scaled)\n",
    "y_pred_prob_tuned = best_rf.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Cakcykate metrics\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test,y_pred_tuned)\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "roc_auc_tuned = roc_auc_score(y_test, y_pred_prob_tuned)\n",
    "print(\"Tuned Random Forest performance:\")\n",
    "print(f\"Accuracy: {accuracy_tuned: .4f}\")\n",
    "print(f\"Precision: {precision_tuned: .4f}\")\n",
    "print(f\"Recall: {recall_tuned: .4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_tuned: .4f}\")\n",
    "\n",
    "# Compare with original\n",
    "print(f\"\\n Improvement in F1-Score: {(f1_tuned - results['Random Forest']['f1']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215b2be-2159-4f66-8f81-695ba50f3cb6",
   "metadata": {},
   "source": [
    "# 10. Bussiness Insights and Recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46525f29-3083-49c7-a710-678ff88e6453",
   "metadata": {},
   "source": [
    "# Analyze key factors contributing to Churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b40d20-567f-4bdd-81b9-d0798dab36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Key Factors Contributing to Customer Churn:\")\n",
    "# 1. Geography\n",
    "geo_churn = df_cleaned.groupby('Geography')['Exited'].mean().sort_values(ascending = False)\n",
    "print(\"\\n1. Churn Rate by Geography: \")\n",
    "for geo, rate in geo_churn.items():\n",
    "    print(f\" {geo}: {rate: .2%}\")\n",
    "\n",
    "# 2. Gender\n",
    "gender_churn = df_cleaned.groupby('Gender')['Exited'].mean()\n",
    "print(\"\\n2. Churn Rage by Gender:\")\n",
    "for gender, rate in gender_churn.items():\n",
    "    print(f\" {gender}: {rate:.2%}\")\n",
    "\n",
    "# 3. Active Membership\n",
    "active_churn = df_cleaned.groupby('IsActiveMember')['Exited'].mean()\n",
    "print(\"\\n3. Churn Rate by Active Membership:\")\n",
    "print(f\"  Inactive Members: {active_churn[0]: .2%}\")\n",
    "print(f\"  Active Members: {active_churn[1]: .2%}\")\n",
    "\n",
    "# 4. Age groups\n",
    "df_cleaned['AgeGroup'] = pd.cut(df_cleaned['Age'],\n",
    "                               bins = [0,30,40,50,60, 100],\n",
    "                               labels = ['<30', '30-40', '40-50','50-60','60+'])\n",
    "age_churn = df_cleaned.groupby('AgeGroup')['Exited'].mean()\n",
    "print(\"\\n4. Churn Rate by Age Group\")\n",
    "for age_group, rate in age_churn.items():\n",
    "    print(f\"  {age_group}: {rate:.2%}\")\n",
    "\n",
    "# 5. Balance analysis\n",
    "high_balance_churn = df_cleaned[df_cleaned['Balance'] > df_cleaned['Balance'].median()]['Exited'].mean()\n",
    "low_balance_churn = df_cleaned[df_cleaned['Balance']<= df_cleaned['Balance'].median()]['Exited'].mean()\n",
    "print('\\n5. Churn Rate by Balance:')\n",
    "print(f\"  High Balance(> median): {high_balance_churn: .2%}\")\n",
    "print(f\"  Low Balance(<= median): {low_balance_churn:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1698d3e-935b-4707-8363-5d7a1b1a22fd",
   "metadata": {},
   "source": [
    "# 11. Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88480643-f0e4-4edd-8cef-442713864fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = 'tuned_random_forest' if 'best_rf' in locals() else 'random_forest'\n",
    "best_model_instance = best_rf if 'best_rf' in locals() else results['Random Forest']['model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732db4a4-4827-49ea-ab4a-500a4b21a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model using joblib\n",
    "joblib.dump(best_model_instance, f'best_churn_model_{best_model_name}.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# save results\n",
    "with open('model_results.pkl', 'wb')as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(f\"Best model saved as 'best_churn_model_{best_model_name}.pkl'\")\n",
    "print(\"Scalar saved as 'scaler.pkl'\")\n",
    "print(\"Results saved as 'model_results.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a8b3e-ccc3-42c3-b8ce-7e1566fca451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for making predictions on new data\n",
    "def predict_churn(customer_data, model_path = 'best_churn_model_tuned_random_forest.pkl',\n",
    "                 scaler_path = 'scaler.pkl'):\n",
    "    \"\"\"\n",
    "    Predict churn for new customer data.\n",
    "\n",
    "    Parameters:\n",
    "    customer_data (DataFrame or dict): New customer data\n",
    "    model_path (str): Path to saved model\n",
    "    scaler_path (str): Path to saved scaler\n",
    "\n",
    "    Returns: \n",
    "    tuple: (prediction, probaility, interpretation)\n",
    "    \"\"\"\n",
    "    #  Load model and scaler\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = jobliv.load(scaler_path)\n",
    "    # convert to DataFrame if dict\n",
    "    if isinstance(customer_data, dict):\n",
    "        customer_df = pd.DataFrame([customer_data])\n",
    "    else:\n",
    "        customer_df = customer_data.copy()\n",
    "\n",
    "    # Preprocess (assuming same preprocessing steps as training)\n",
    "    # Drop irrelevant columns if present\n",
    "    cols_to_drop = ['RowNumber', 'CustomerId', 'Surname']\n",
    "    for col in cols_to_drop:\n",
    "        if col in customer_df.columns:\n",
    "            customer_df = customer_df.drop(col, axis = 1)\n",
    "    # one-hot encode categorical variables\n",
    "    customer_df = pd.get_dummies(customer_df, columns = ['Geography', 'Gender'], drop_first = True)\n",
    "    # Ensure all expected columns are present\n",
    "    expected_cols = X_train.columns.tolist()\n",
    "    for col in expected_cols:\n",
    "        if col not in customer_df.columns:\n",
    "            customer_df[col] = 0\n",
    "    # Reorder columns\n",
    "    customer_df= customer_df[expected_cols]\n",
    "\n",
    "    # Scale numerical features\n",
    "    num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "    customer_df[num_cols] = scaler.transform(customer_df[num_cols])\n",
    "\n",
    "    # Make Prediction \n",
    "    prediction = model.predict(customer_df)[0]\n",
    "    probability = model.predict_proba(customer_df)[0][1]\n",
    "\n",
    "    # Interpretation\n",
    "    interpretation = 'High risk of churn' if prediction == 1 else \"Low risk of churn\"\n",
    "    return prediction, probability, interpretation\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465581e-7be8-4b5c-ae42-2f99c1026ede",
   "metadata": {},
   "source": [
    "# 12. Conclusion and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25356fa-e5de-4e4d-9567-560c1e761df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*60)\n",
    "print(\"CUSTOMER CHURN PREDICTION PROJECT - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDataset: {df.shape[0]} customers, {df.shape[1]} features\")\n",
    "print(f\"Churn Rate: {df_cleaned['Exited'].mean():.2%}\")\n",
    "\n",
    "print(\"\\nBest Performing Model:\")\n",
    "best_model_name = results_df.loc[results_df['F1-Score'].idxmax(), 'Model']\n",
    "best_metrics = results_df.loc[results_df['F1-Score'].idxmax()]\n",
    "print(f\"  Model: {best_model_name}\")\n",
    "print(f\"  F1-Score: {best_metrics['F1-Score']:.4f}\")\n",
    "print(f\"  Accuracy: {best_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Recall: {best_metrics['Recall']:.4f}\")\n",
    "print(f\"  Precision: {best_metrics['Precision']:.4f}\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"1. Geography: Germany has the highest churn rate\")\n",
    "print(\"2. Age: Older customers are more likely to churn\")\n",
    "print(\"3. Activity: Inactive members have higher churn rates\")\n",
    "print(\"4. Products: Customers with 1 product have highest churn\")\n",
    "print(\"5. Balance: Customers with high balance are more likely to churn\")\n",
    "\n",
    "print(\"\\nBusiness Recommendations:\")\n",
    "print(\"1. Focus retention efforts on German customers\")\n",
    "print(\"2. Create engagement programs for inactive members\")\n",
    "print(\"3. Develop targeted offers for customers with single products\")\n",
    "print(\"4. Implement loyalty programs for high-balance customers\")\n",
    "print(\"5. Use the model to identify at-risk customers proactively\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Project completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
